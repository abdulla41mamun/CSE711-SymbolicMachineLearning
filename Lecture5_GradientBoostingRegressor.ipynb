{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaYE2yaZ80h+uHIgJ3RoW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulla41mamun/CSE711-SymbolicMachineLearning/blob/main/Lecture5_GradientBoostingRegressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvPJ8mF79SiU",
        "outputId": "909919ab-749c-4dd0-eabe-110de38bd454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            " Gradient Boosting for Regression Example\n",
            "==================================================\n",
            "\n",
            "--- Initial Dataset (Slide 2) ---\n",
            "\n",
            "   Age Place of living  IQ-score\n",
            "0    8         Village         1\n",
            "1   10            City         3\n",
            "2   12         Village         1\n",
            "3   30         Village         4\n",
            "4   35            City         5\n",
            "5   60            City         2\n",
            "\n",
            "\n",
            "--- Step 1: Initial Prediction and Residuals (Slide 3) ---\n",
            "Initial Prediction (Average IQ-Score): 2.6666667\n",
            "\n",
            "DataFrame with Initial Prediction and Residuals:\n",
            "\n",
            "   Age Place of living  IQ-score  Predicted_IQ  Pseudo_Residual_1\n",
            "0    8         Village         1     2.6666667         -1.6666667\n",
            "1   10            City         3     2.6666667          0.3333333\n",
            "2   12         Village         1     2.6666667         -1.6666667\n",
            "3   30         Village         4     2.6666667          1.3333333\n",
            "4   35            City         5     2.6666667          2.3333333\n",
            "5   60            City         2     2.6666667         -0.6666667\n",
            "\n",
            "\n",
            "--- Step 2: Building the First Tree (Finding best split for 'Age') (Slide 5) ---\n",
            "\n",
            "Calculating Sum of Squared Residuals (SSR) for each potential split:\n",
            "Split at Age < 9.0: Left Avg=-1.6666667, Right Avg=0.3333333, Total SSR=10.0000000\n",
            "Split at Age < 11.0: Left Avg=-0.6666667, Right Avg=0.3333333, Total SSR=12.0000000\n",
            "Split at Age < 21.0: Left Avg=-1.0000000, Right Avg=1.0000000, Total SSR=7.3333333\n",
            "Split at Age < 32.5: Left Avg=-0.4166667, Right Avg=0.8333333, Total SSR=11.2500000\n",
            "Split at Age < 47.5: Left Avg=0.1333333, Right Avg=-0.6666667, Total SSR=12.8000000\n",
            "\n",
            "Best Split for 'Age' is at: 21.0 with a minimum SSR of 7.3333333 (Matches Slide 8)\n",
            "\n",
            "First Tree Leaf Values (Slide 10):\n",
            "  - Leaf 1 (Age < 21.0): -1.0000000\n",
            "  - Leaf 2 (Age >= 21.0): 1.0000000\n",
            "\n",
            "\n",
            "--- Step 3: Update Predictions with First Tree (Learning Rate = 0.1) (Slide 11) ---\n",
            "\n",
            "DataFrame with Updated Predictions and New Residuals:\n",
            "\n",
            "   IQ-score  Predicted_IQ  Tree1_Output  Predicted_IQ_2  Pseudo_Residual_2\n",
            "0         1     2.6666667    -1.0000000       2.5666667         -1.5666667\n",
            "1         3     2.6666667    -1.0000000       2.5666667          0.4333333\n",
            "2         1     2.6666667    -1.0000000       2.5666667         -1.5666667\n",
            "3         4     2.6666667     1.0000000       2.7666667          1.2333333\n",
            "4         5     2.6666667     1.0000000       2.7666667          2.2333333\n",
            "5         2     2.6666667     1.0000000       2.7666667         -0.7666667\n",
            "\n",
            "\n",
            "--- Step 4: Building the Second Tree (Finding best split for 'Age') (Slide 12) ---\n",
            "\n",
            "Calculating SSR for each potential split using new residuals:\n",
            "Split at Age < 9.0: Left Avg=-1.5666667, Right Avg=0.3133333, Total SSR=9.2480000\n",
            "Split at Age < 11.0: Left Avg=-0.5666667, Right Avg=0.2833333, Total SSR=11.2300000\n",
            "Split at Age < 21.0: Left Avg=-0.9000000, Right Avg=0.9000000, Total SSR=7.3333333\n",
            "Split at Age < 32.5: Left Avg=-0.3666667, Right Avg=0.7333333, Total SSR=10.5800000\n",
            "Split at Age < 47.5: Left Avg=0.1533333, Right Avg=-0.7666667, Total SSR=11.4880000\n",
            "\n",
            "Best Split for 'Age' in Second Tree is at: 21.0 with a minimum SSR of 7.3333333 (Matches Slide 12)\n",
            "\n",
            "Second Tree Leaf Values (Slide 14):\n",
            "  - Leaf 1 (Age < 21.0): -0.9000000\n",
            "  - Leaf 2 (Age >= 21.0): 0.9000000\n",
            "\n",
            "\n",
            "--- Step 5: Final Predictions after Second Tree (Slide 16) ---\n",
            "\n",
            "Final DataFrame:\n",
            "\n",
            "   Age  IQ-score  Predicted_IQ  Predicted_IQ_2  Predicted_IQ_Final\n",
            "0    8         1     2.6666667       2.5666667           2.4766667\n",
            "1   10         3     2.6666667       2.5666667           2.4766667\n",
            "2   12         1     2.6666667       2.5666667           2.4766667\n",
            "3   30         4     2.6666667       2.7666667           2.8566667\n",
            "4   35         5     2.6666667       2.7666667           2.8566667\n",
            "5   60         2     2.6666667       2.7666667           2.8566667\n",
            "\n",
            "\n",
            "==================================================\n",
            " Gradient Boosting for Classification Example\n",
            "==================================================\n",
            "\n",
            "--- Initial Dataset (Slide 17) ---\n",
            "\n",
            "   Age Place of living IQ-score_cat  Y\n",
            "0    8         Village          Low  1\n",
            "1   10            City          Low  1\n",
            "2   12         Village          Low  1\n",
            "3   30         Village         High  0\n",
            "4   35            City         High  0\n",
            "5   60            City          Low  1\n",
            "\n",
            "\n",
            "--- Step 1: Initial Prediction and Residuals (Slide 19) ---\n",
            "Initial Log(Odds): 0.6931472\n",
            "Initial Probability: 0.6666667\n",
            "\n",
            "DataFrame with Initial Prediction and Residuals:\n",
            "\n",
            "   Age  Y  Log_Odds_1    Prob_1  Residual_1\n",
            "0    8  1   0.6931472 0.6666667   0.3333333\n",
            "1   10  1   0.6931472 0.6666667   0.3333333\n",
            "2   12  1   0.6931472 0.6666667   0.3333333\n",
            "3   30  0   0.6931472 0.6666667  -0.6666667\n",
            "4   35  0   0.6931472 0.6666667  -0.6666667\n",
            "5   60  1   0.6931472 0.6666667   0.3333333\n",
            "\n",
            "\n",
            "--- Step 2: Building the First Tree (Finding best split for 'Age') (Slide 20) ---\n",
            "\n",
            "Calculating Sum of Squared Residuals (SSR) for each potential split:\n",
            "Split at Age < 9.0: Left Avg=0.3333333, Right Avg=-0.0666667, Total SSR=1.2000000\n",
            "Split at Age < 11.0: Left Avg=0.3333333, Right Avg=-0.1666667, Total SSR=1.0000000\n",
            "Split at Age < 21.0: Left Avg=0.3333333, Right Avg=-0.3333333, Total SSR=0.6666667\n",
            "Split at Age < 32.5: Left Avg=0.0833333, Right Avg=-0.1666667, Total SSR=1.2500000\n",
            "Split at Age < 47.5: Left Avg=-0.0666667, Right Avg=0.3333333, Total SSR=1.2000000\n",
            "\n",
            "Best Split for 'Age' is at: 21.0 with a minimum SSR of 0.6666667 (Matches Slide 21)\n",
            "\n",
            "\n",
            "--- Step 3: Calculating Leaf Output Values (Slide 22) ---\n",
            "First Tree Leaf Values:\n",
            "  - Leaf 1 (Age < 21.0): 1.5000000 (Matches ~1.49-1.50 on Slide 23)\n",
            "  - Leaf 2 (Age >= 21.0): -1.5000000 (Matches ~-1.52 on Slide 23)\n",
            "\n",
            "\n",
            "--- Step 4: Update Log(Odds) and Probabilities (Learning Rate = 0.6) (Slide 24) ---\n",
            "\n",
            "Final DataFrame with updated probabilities:\n",
            "\n",
            "   Age Place of living IQ-score  Encoded IQ-score (Y)  Predicted Probability   Residual  log(Odds)\n",
            "0    8         Village      Low                     1              0.8310584  0.1689416  1.5931472\n",
            "1   10            City      Low                     1              0.8310584  0.1689416  1.5931472\n",
            "2   12         Village      Low                     1              0.8310584  0.1689416  1.5931472\n",
            "3   30         Village     High                     0              0.4484704 -0.4484704 -0.2068528\n",
            "4   35            City     High                     0              0.4484704 -0.4484704 -0.2068528\n",
            "5   60            City      Low                     1              0.4484704  0.5515296 -0.2068528\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set display options for pandas for better visibility\n",
        "pd.set_option('display.float_format', '{:.7f}'.format)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "def run_regression_example():\n",
        "    \"\"\"\n",
        "    This function implements the Gradient Boosting for Regression example\n",
        "    as shown in the presentation slides.\n",
        "    \"\"\"\n",
        "    print(\"=\"*50)\n",
        "    print(\" Gradient Boosting for Regression Example\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # --- Step 1: Initial Data and First Prediction ---\n",
        "    # As per Slide 2\n",
        "    data = {\n",
        "        'Age': [8, 10, 12, 30, 35, 60],\n",
        "        'Place of living': ['Village', 'City', 'Village', 'Village', 'City', 'City'],\n",
        "        'IQ-score': [1, 3, 1, 4, 5, 2]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"\\n--- Initial Dataset (Slide 2) ---\\n\")\n",
        "    print(df)\n",
        "\n",
        "    # Calculate the initial prediction: the average of the target variable\n",
        "    # As per Slide 3\n",
        "    initial_prediction = df['IQ-score'].mean()\n",
        "    df['Predicted_IQ'] = initial_prediction\n",
        "    df['Pseudo_Residual_1'] = df['IQ-score'] - df['Predicted_IQ']\n",
        "\n",
        "    print(f\"\\n\\n--- Step 1: Initial Prediction and Residuals (Slide 3) ---\")\n",
        "    print(f\"Initial Prediction (Average IQ-Score): {initial_prediction:.7f}\")\n",
        "    print(\"\\nDataFrame with Initial Prediction and Residuals:\\n\")\n",
        "    print(df[['Age', 'Place of living', 'IQ-score', 'Predicted_IQ', 'Pseudo_Residual_1']])\n",
        "\n",
        "    # --- Step 2: Build the First Decision Tree ---\n",
        "    # We need to find the best split for 'Age' that minimizes the Sum of Squared Residuals (SSR)\n",
        "    # As per Slide 5\n",
        "    print(\"\\n\\n--- Step 2: Building the First Tree (Finding best split for 'Age') (Slide 5) ---\")\n",
        "    ages = sorted(df['Age'].unique())\n",
        "    split_points = [(ages[i] + ages[i+1]) / 2 for i in range(len(ages)-1)]\n",
        "    min_ssr = float('inf')\n",
        "    best_split = None\n",
        "\n",
        "    print(\"\\nCalculating Sum of Squared Residuals (SSR) for each potential split:\")\n",
        "    for split in split_points:\n",
        "        left_mask = df['Age'] < split\n",
        "        right_mask = df['Age'] >= split\n",
        "\n",
        "        avg_left = df.loc[left_mask, 'Pseudo_Residual_1'].mean()\n",
        "        avg_right = df.loc[right_mask, 'Pseudo_Residual_1'].mean()\n",
        "\n",
        "        ssr_left = ((df.loc[left_mask, 'Pseudo_Residual_1'] - avg_left)**2).sum()\n",
        "        ssr_right = ((df.loc[right_mask, 'Pseudo_Residual_1'] - avg_right)**2).sum()\n",
        "        total_ssr = ssr_left + ssr_right\n",
        "\n",
        "        print(f\"Split at Age < {split}: Left Avg={avg_left:.7f}, Right Avg={avg_right:.7f}, Total SSR={total_ssr:.7f}\")\n",
        "\n",
        "        if total_ssr < min_ssr:\n",
        "            min_ssr = total_ssr\n",
        "            best_split = split\n",
        "\n",
        "    print(f\"\\nBest Split for 'Age' is at: {best_split} with a minimum SSR of {min_ssr:.7f} (Matches Slide 8)\")\n",
        "\n",
        "    # Calculate leaf node output values (average of residuals in each leaf)\n",
        "    # As per Slide 10\n",
        "    left_leaf_value_1 = df.loc[df['Age'] < best_split, 'Pseudo_Residual_1'].mean()\n",
        "    right_leaf_value_1 = df.loc[df['Age'] >= best_split, 'Pseudo_Residual_1'].mean()\n",
        "    print(f\"\\nFirst Tree Leaf Values (Slide 10):\")\n",
        "    print(f\"  - Leaf 1 (Age < {best_split}): {left_leaf_value_1:.7f}\")\n",
        "    print(f\"  - Leaf 2 (Age >= {best_split}): {right_leaf_value_1:.7f}\")\n",
        "\n",
        "    # --- Step 3: Update Predictions and Calculate New Residuals ---\n",
        "    # As per Slide 11\n",
        "    learning_rate = 0.1\n",
        "    df['Tree1_Output'] = np.where(df['Age'] < best_split, left_leaf_value_1, right_leaf_value_1)\n",
        "    df['Predicted_IQ_2'] = df['Predicted_IQ'] + learning_rate * df['Tree1_Output']\n",
        "    df['Pseudo_Residual_2'] = df['IQ-score'] - df['Predicted_IQ_2']\n",
        "\n",
        "    print(f\"\\n\\n--- Step 3: Update Predictions with First Tree (Learning Rate = {learning_rate}) (Slide 11) ---\")\n",
        "    print(\"\\nDataFrame with Updated Predictions and New Residuals:\\n\")\n",
        "    print(df[['IQ-score', 'Predicted_IQ', 'Tree1_Output', 'Predicted_IQ_2', 'Pseudo_Residual_2']])\n",
        "\n",
        "    # --- Step 4: Build the Second Decision Tree ---\n",
        "    # As per Slide 12\n",
        "    print(\"\\n\\n--- Step 4: Building the Second Tree (Finding best split for 'Age') (Slide 12) ---\")\n",
        "    min_ssr_2 = float('inf')\n",
        "    best_split_2 = None\n",
        "\n",
        "    print(\"\\nCalculating SSR for each potential split using new residuals:\")\n",
        "    for split in split_points:\n",
        "        left_mask = df['Age'] < split\n",
        "        right_mask = df['Age'] >= split\n",
        "\n",
        "        avg_left = df.loc[left_mask, 'Pseudo_Residual_2'].mean()\n",
        "        avg_right = df.loc[right_mask, 'Pseudo_Residual_2'].mean()\n",
        "\n",
        "        ssr_left = ((df.loc[left_mask, 'Pseudo_Residual_2'] - avg_left)**2).sum()\n",
        "        ssr_right = ((df.loc[right_mask, 'Pseudo_Residual_2'] - avg_right)**2).sum()\n",
        "        total_ssr = ssr_left + ssr_right\n",
        "\n",
        "        print(f\"Split at Age < {split}: Left Avg={avg_left:.7f}, Right Avg={avg_right:.7f}, Total SSR={total_ssr:.7f}\")\n",
        "\n",
        "        if total_ssr < min_ssr_2:\n",
        "            min_ssr_2 = total_ssr\n",
        "            best_split_2 = split\n",
        "\n",
        "    print(f\"\\nBest Split for 'Age' in Second Tree is at: {best_split_2} with a minimum SSR of {min_ssr_2:.7f} (Matches Slide 12)\")\n",
        "\n",
        "    # Calculate leaf node output values for the second tree\n",
        "    # As per Slide 14\n",
        "    left_leaf_value_2 = df.loc[df['Age'] < best_split_2, 'Pseudo_Residual_2'].mean()\n",
        "    right_leaf_value_2 = df.loc[df['Age'] >= best_split_2, 'Pseudo_Residual_2'].mean()\n",
        "    print(f\"\\nSecond Tree Leaf Values (Slide 14):\")\n",
        "    print(f\"  - Leaf 1 (Age < {best_split_2}): {left_leaf_value_2:.7f}\")\n",
        "    print(f\"  - Leaf 2 (Age >= {best_split_2}): {right_leaf_value_2:.7f}\")\n",
        "\n",
        "    # --- Step 5: Final Prediction ---\n",
        "    # As per Slide 16\n",
        "    df['Tree2_Output'] = np.where(df['Age'] < best_split_2, left_leaf_value_2, right_leaf_value_2)\n",
        "    df['Predicted_IQ_Final'] = df['Predicted_IQ_2'] + learning_rate * df['Tree2_Output']\n",
        "\n",
        "    print(f\"\\n\\n--- Step 5: Final Predictions after Second Tree (Slide 16) ---\")\n",
        "    print(\"\\nFinal DataFrame:\\n\")\n",
        "    print(df[['Age', 'IQ-score', 'Predicted_IQ', 'Predicted_IQ_2', 'Predicted_IQ_Final']])\n",
        "\n",
        "\n",
        "def run_classification_example():\n",
        "    \"\"\"\n",
        "    This function implements the Gradient Boosting for Classification example\n",
        "    as shown in the presentation slides.\n",
        "    \"\"\"\n",
        "    print(\"\\n\\n\" + \"=\"*50)\n",
        "    print(\" Gradient Boosting for Classification Example\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # --- Step 1: Initial Data and First Prediction ---\n",
        "    # As per Slide 17\n",
        "    data = {\n",
        "        'Age': [8, 10, 12, 30, 35, 60],\n",
        "        'Place of living': ['Village', 'City', 'Village', 'Village', 'City', 'City'],\n",
        "        'IQ-score_cat': ['Low', 'Low', 'Low', 'High', 'High', 'Low']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    # Encode target variable: Low = 1, High = 0\n",
        "    df['Y'] = np.where(df['IQ-score_cat'] == 'Low', 1, 0)\n",
        "    print(\"\\n--- Initial Dataset (Slide 17) ---\\n\")\n",
        "    print(df)\n",
        "\n",
        "    # Calculate initial log(odds)\n",
        "    # As per Slide 19\n",
        "    num_low = df[df['Y'] == 1].shape[0]\n",
        "    num_high = df[df['Y'] == 0].shape[0]\n",
        "    initial_log_odds = np.log(num_low / num_high)\n",
        "\n",
        "    # Calculate initial probability\n",
        "    initial_prob = np.exp(initial_log_odds) / (1 + np.exp(initial_log_odds))\n",
        "\n",
        "    df['Log_Odds_1'] = initial_log_odds\n",
        "    df['Prob_1'] = initial_prob\n",
        "    df['Residual_1'] = df['Y'] - df['Prob_1']\n",
        "\n",
        "    print(f\"\\n\\n--- Step 1: Initial Prediction and Residuals (Slide 19) ---\")\n",
        "    print(f\"Initial Log(Odds): {initial_log_odds:.7f}\")\n",
        "    print(f\"Initial Probability: {initial_prob:.7f}\")\n",
        "    print(\"\\nDataFrame with Initial Prediction and Residuals:\\n\")\n",
        "    print(df[['Age', 'Y', 'Log_Odds_1', 'Prob_1', 'Residual_1']])\n",
        "\n",
        "    # --- Step 2: Build the First Decision Tree ---\n",
        "    # As per Slide 20\n",
        "    print(\"\\n\\n--- Step 2: Building the First Tree (Finding best split for 'Age') (Slide 20) ---\")\n",
        "    ages = sorted(df['Age'].unique())\n",
        "    split_points = [(ages[i] + ages[i+1]) / 2 for i in range(len(ages)-1)]\n",
        "    min_ssr = float('inf')\n",
        "    best_split = None\n",
        "\n",
        "    print(\"\\nCalculating Sum of Squared Residuals (SSR) for each potential split:\")\n",
        "    for split in split_points:\n",
        "        left_mask = df['Age'] < split\n",
        "        right_mask = df['Age'] >= split\n",
        "\n",
        "        avg_left = df.loc[left_mask, 'Residual_1'].mean()\n",
        "        avg_right = df.loc[right_mask, 'Residual_1'].mean()\n",
        "\n",
        "        ssr_left = ((df.loc[left_mask, 'Residual_1'] - avg_left)**2).sum()\n",
        "        ssr_right = ((df.loc[right_mask, 'Residual_1'] - avg_right)**2).sum()\n",
        "        total_ssr = ssr_left + ssr_right\n",
        "\n",
        "        print(f\"Split at Age < {split}: Left Avg={avg_left:.7f}, Right Avg={avg_right:.7f}, Total SSR={total_ssr:.7f}\")\n",
        "\n",
        "        if total_ssr < min_ssr:\n",
        "            min_ssr = total_ssr\n",
        "            best_split = split\n",
        "\n",
        "    print(f\"\\nBest Split for 'Age' is at: {best_split} with a minimum SSR of {min_ssr:.7f} (Matches Slide 21)\")\n",
        "\n",
        "    # --- Step 3: Calculate Leaf Output Values ---\n",
        "    # As per Slide 22\n",
        "    print(\"\\n\\n--- Step 3: Calculating Leaf Output Values (Slide 22) ---\")\n",
        "    left_mask = df['Age'] < best_split\n",
        "    right_mask = df['Age'] >= best_split\n",
        "\n",
        "    numerator_left = df.loc[left_mask, 'Residual_1'].sum()\n",
        "    denominator_left = (df.loc[left_mask, 'Prob_1'] * (1 - df.loc[left_mask, 'Prob_1'])).sum()\n",
        "    leaf_value_left = numerator_left / denominator_left\n",
        "\n",
        "    numerator_right = df.loc[right_mask, 'Residual_1'].sum()\n",
        "    denominator_right = (df.loc[right_mask, 'Prob_1'] * (1 - df.loc[right_mask, 'Prob_1'])).sum()\n",
        "    leaf_value_right = numerator_right / denominator_right\n",
        "\n",
        "    print(f\"First Tree Leaf Values:\")\n",
        "    print(f\"  - Leaf 1 (Age < {best_split}): {leaf_value_left:.7f} (Matches ~1.49-1.50 on Slide 23)\")\n",
        "    print(f\"  - Leaf 2 (Age >= {best_split}): {leaf_value_right:.7f} (Matches ~-1.52 on Slide 23)\")\n",
        "\n",
        "    # --- Step 4: Update Log(Odds) and Probabilities ---\n",
        "    # As per Slide 24\n",
        "    learning_rate = 0.6 # From slide 23\n",
        "    df['Tree1_Output'] = np.where(df['Age'] < best_split, leaf_value_left, leaf_value_right)\n",
        "    df['Log_Odds_2'] = df['Log_Odds_1'] + learning_rate * df['Tree1_Output']\n",
        "    df['Prob_2'] = np.exp(df['Log_Odds_2']) / (1 + np.exp(df['Log_Odds_2']))\n",
        "    df['Residual_2'] = df['Y'] - df['Prob_2']\n",
        "\n",
        "    print(f\"\\n\\n--- Step 4: Update Log(Odds) and Probabilities (Learning Rate = {learning_rate}) (Slide 24) ---\")\n",
        "    print(\"\\nFinal DataFrame with updated probabilities:\\n\")\n",
        "    # To match the slide's final table format\n",
        "    final_output = df[['Age', 'Place of living', 'IQ-score_cat', 'Y', 'Prob_2', 'Residual_2', 'Log_Odds_2']]\n",
        "    final_output = final_output.rename(columns={\n",
        "        'IQ-score_cat': 'IQ-score',\n",
        "        'Y': 'Encoded IQ-score (Y)',\n",
        "        'Prob_2': 'Predicted Probability',\n",
        "        'Residual_2': 'Residual',\n",
        "        'Log_Odds_2': 'log(Odds)'\n",
        "    })\n",
        "    print(final_output)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_regression_example()\n",
        "    run_classification_example()\n"
      ]
    }
  ]
}